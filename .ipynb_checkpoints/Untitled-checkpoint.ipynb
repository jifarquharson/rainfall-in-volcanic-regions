{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137b07dd",
   "metadata": {},
   "source": [
    "## Volcanic hazard exacerbated by future global warming–driven increase in heavy rainfall\n",
    "### Jamie I. Farquharson, Falk Amelung\n",
    "Rosenstiel School of Marine and Atmospheric Science, University of Miami, Miami, FL, USA\n",
    "\n",
    "Corresponding author: jifarq89@googlemail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086533ad",
   "metadata": {},
   "source": [
    "### Supplementary analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a953a378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamiefarquharson/Documents/GitHub/rainfall-in-volcanic-regions\n",
      "'data' directory already exists\n",
      "'climate_mods' directory already exists\n",
      "'climate_figures' directory already exists\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "filepath will point to current location of the Jupyter Notebook.\n",
    "Creates directories if necessary.\n",
    "'''\n",
    "import os\n",
    "from os import path\n",
    "os.getcwd()\n",
    "!pwd\n",
    "def make_tree(directory):\n",
    "    d = directory\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "    else:\n",
    "        print(\"'{}' directory already exists\".format(d))\n",
    "make_tree(\"data\")\n",
    "make_tree(\"climate_mods\")\n",
    "make_tree(\"climate_figures\")\n",
    "work_dir = os.path.expanduser('work_dir')\n",
    "filepath = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a6746-eba3-4288-a278-5fb023b21b02",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d94c32f-db6d-444d-b443-55e0e6edf3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Import packages\n",
    "'''\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib as matplotlib\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import patheffects\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "buffer = [patheffects.withStroke(linewidth=1, foreground=\"w\", alpha = 0.85)]\n",
    "plt.rcParams[\"font.family\"] = 'sans-serif'\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Computer Modern Sans serif']\n",
    "plt.rcParams[\"font.family\"] = 'sans-serif'\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = ['Palatino']\n",
    "params = {'text.latex.preamble' : [r'\\usepackage{amsmath}', r'\\usepackage{amssymb}']}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy import sparse\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import os\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import glob\n",
    "import string as STRING\n",
    "import fnmatch\n",
    "import time\n",
    "import pylab\n",
    "import hashlib\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import chisquare\n",
    "print(\"All packages imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f77b8886-aada-4ed9-a9ee-8c0ac8d1be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/jamiefarquharson/Desktop/RSMAS/Eruption_ntbk'# 'path/to/directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8609f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamiefarquharson/Desktop/RSMAS/Eruption_ntbk\n"
     ]
    }
   ],
   "source": [
    "if os.getcwd() != filepath:\n",
    "    %cd $filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a41fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function converts mm input to inches (for plotting figures the correct size).\n",
    "'''\n",
    "\n",
    "def mm2inch(*tupl):\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(k*0.0393701 for k in tupl[0])\n",
    "    else:\n",
    "        return tuple(k*0.0393701 for k in tupl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a40ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_plt_params():\n",
    "    matplotlib.rcParams['text.usetex'] = True \n",
    "    matplotlib.rcParams['text.latex.preamble'] = [r'\\usepackage[cm]{sfmath}']\n",
    "    matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "    matplotlib.rcParams['font.sans-serif'] = 'cm'\n",
    "    plt.rcParams[\"font.family\"] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020e589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c52e5f88",
   "metadata": {},
   "source": [
    "### Functions for reading and processing climate data\n",
    "\n",
    "####  Model output data have been obtained through Earth System Grid Federation servers, in particular the node hosted by the Lawrence Livermore National Laboratory https://esgf-node.llnl.gov/search/cmip5/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6261348",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Models used '''\n",
    "fileNameCodes = [['NorESM1-M',\n",
    "  'CSIRO-Mk3-6-0',\n",
    "  'MRI-CGCM3',\n",
    "  'ACCESS1-3',\n",
    "  'inmcm4',\n",
    "  'MIROC5',\n",
    "  'IPSL-CM5A-MR',\n",
    "  'CanESM2',\n",
    "  'CNRM-CM5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21affb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b180374f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c20289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_models(parameter = \"pr\", modelName =\"\", rcp45=False):\n",
    "    import glob as glob\n",
    "    if rcp45==True:\n",
    "        models = [mod for mod in glob.glob(\"climate_mods/rcp45/{}*\".format(parameter))]\n",
    "    else:\n",
    "        models = [mod for mod in glob.glob(\"climate_mods/rcp85/{}*\".format(parameter))]\n",
    "    modelList = []\n",
    "    for modelString in models:\n",
    "        if modelName in modelString:\n",
    "            modelList.append(modelString)\n",
    "    return sorted(modelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7136900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_models_rcp26(parameter = \"pr\", modelName =\"\"):\n",
    "    import glob as glob\n",
    "    models = [mod for mod in glob.glob(\"climate_mods/rcp26/{}*\".format(parameter))]\n",
    "    modelList = []\n",
    "    for modelString in models:\n",
    "        if modelName in modelString:\n",
    "            modelList.append(modelString)\n",
    "    return sorted(modelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7398e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24bdef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38b8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean_temp(modelName, method = \"max\", verbose = False, rcp45=False):\n",
    "    ''' \"how\" can be either \"max\" or \"mean\" '''\n",
    "    import netCDF4\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        modelFile = netCDF4.MFDataset(list_of_models(parameter=\"ta\", modelName=modelName, rcp45=rcp45))\n",
    "        startString = modelFile.variables[\"time\"].units.split()[2] # Days since XXX date\n",
    "        start = datetime.strptime(startString, \"%Y-%m-%d\")\n",
    "        time = [start+timedelta(int(x)) for x in modelFile.variables[\"time\"][:]]\n",
    "        model_gmT = []\n",
    "        for x in range(modelFile.variables[\"ta\"].shape[0]):\n",
    "            model_gmT.append(np.nanmean(modelFile.variables[\"ta\"][x][0]))\n",
    "        gmT_df = pd.DataFrame(\n",
    "    {'ix':time,'date':time, ##\n",
    "     'temp': model_gmT\n",
    "    })\n",
    "        gmT_df=gmT_df.set_index('ix')\n",
    "        gmT_df.index = pd.to_datetime(gmT_df.index)\n",
    "        gmT = gmT_df.resample(\"Y\").agg(method)#, how=method)\n",
    "\n",
    "\n",
    "        modelFile.close()\n",
    "        if verbose == True:\n",
    "            print(\"{} succesfully processed\".format(modelName))\n",
    "        return gmT, gmT_df\n",
    "    except:\n",
    "        print(\"Error reading {}\".format(modelName))\n",
    "\n",
    "def heavy_rainfall(i_volc, j_volc, modelName=\"\", method = \"max\", verbose = False, rcp45 = False):\n",
    "    ''' \"how\" method deprecated, use .agg(). Can be either \"max\" or \"mean\" '''\n",
    "    import netCDF4\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        modelFile = netCDF4.MFDataset(list_of_models(parameter=\"pr\", modelName=modelName, rcp45=rcp45))\n",
    "        startString = modelFile.variables[\"time\"].units.split()[2] # Days since XXX date\n",
    "        start = datetime.strptime(startString, \"%Y-%m-%d\")\n",
    "        time = [start+timedelta(int(x)) for x in modelFile.variables[\"time\"][:]]\n",
    "        rx_volc = []\n",
    "        lat_vals = modelFile.variables[\"lat\"][:]\n",
    "        lon_vals = modelFile.variables[\"lon\"][:]\n",
    "        i = int(np.where(lat_vals==i_volc)[0])\n",
    "        j = int(np.where(lon_vals==j_volc)[0])\n",
    "        prcp = list(modelFile.variables[\"pr\"][:,i,j])\n",
    "        temp_df = pd.DataFrame(\n",
    "    {'ix':time,'date':time, ##\n",
    "     'rainfall': prcp\n",
    "    })\n",
    "        temp_df=temp_df.set_index('ix')\n",
    "        temp_df.index = pd.to_datetime(temp_df.index)\n",
    "        RX1 = temp_df.resample(\"Y\").agg(method)#, how=method)\n",
    "        modelFile.close()\n",
    "        if verbose == True:\n",
    "            print(\"{} succesfully processed\".format(modelName))\n",
    "        return temp_df, RX1\n",
    "    except:\n",
    "        print(\"Error reading {}\".format(modelName))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c20b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_FMR(modelName=\"\", resampled_gmT=\"\", method = \"max\", verbose = False, rcp45 = False):\n",
    "    ''' \"how\" method deprecated, use .agg(). Can be either \"max\" or \"mean\" '''\n",
    "    try:\n",
    "        modelFile = netCDF4.MFDataset(list_of_models(parameter=\"pr\", modelName=modelName, rcp45=rcp45))\n",
    "        startString = modelFile.variables[\"time\"].units.split()[2] # Days since XXX date\n",
    "        start = datetime.strptime(startString, \"%Y-%m-%d\")\n",
    "        time = [start+timedelta(int(x)) for x in modelFile.variables[\"time\"][:]]\n",
    "        rx1 = []\n",
    "        lat_vals = modelFile.variables[\"lat\"][:]\n",
    "        lon_vals = modelFile.variables[\"lon\"][:]\n",
    "\n",
    "        count = len(lat_vals)\n",
    "        bar_size=40\n",
    "        for j, lat in enumerate(lat_vals):\n",
    "            for k, lon in enumerate(lon_vals):\n",
    "                prcp = list(modelFile[\"pr\"][:,j,k])\n",
    "                temp_df = pd.DataFrame(\n",
    "            {'ix':time,'date':time, ##\n",
    "             'rainfall': prcp\n",
    "            })\n",
    "                temp_df=temp_df.set_index('ix')\n",
    "                temp_df.index = pd.to_datetime(temp_df.index)\n",
    "                RX1 = temp_df.resample(\"Y\").agg(method)\n",
    "\n",
    "                gmT = resampled_gmT #temp_df.resample(\"Y\").agg(\"mean\")\n",
    "                timeframe = [int(x) for x in np.linspace(RX1.index[0].year, RX1.index[-1].year,len(RX1.rainfall))]\n",
    "                RX1val = [x for x in RX1.rainfall.values]\n",
    "                gmTval = [x for x in gmT.temp.values]\n",
    "                gmTval_n = [x - gmTval[1] for x in gmTval[1::]]\n",
    "                RX1val_n = [(x-RX1val[1])/RX1val[1]*100 for x in RX1val[1::]]\n",
    "\n",
    "                mask = ~np.isnan(gmTval_n) & ~np.isnan(RX1val_n)\n",
    "                m, c, r, p, s = linregress(\n",
    "                    np.array(gmTval_n)[mask],\n",
    "                    np.array(RX1val_n)[mask])\n",
    "                rx1.append(m)\n",
    "            bar_frac = int(bar_size*(j+1)/count)\n",
    "            print(\"{} {} rainfall: |{}{}| {}/{}\".format(\"Processing\",modelName,\n",
    "                                               u\"█\"*bar_frac, u\"\\u22c5\"*(bar_size-bar_frac),\n",
    "                                               j+1, count), \n",
    "            end='\\r', file=sys.stdout, flush=True)\n",
    "        modelFile.close()\n",
    "        rx1_rs=np.reshape(rx1, (len(lat_vals),len(lon_vals)))\n",
    "        print(\"\\n{} data reshaped  \".format(modelName))\n",
    "        return rx1, rx1_rs\n",
    "   \n",
    "    except:\n",
    "#         print(\"Error reading {}\".format(modelName))\n",
    "        funcName = sys._getframe().f_code.co_name\n",
    "        print(\"Error reading {} ({})\".format(modelName, funcName))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c42ff",
   "metadata": {},
   "source": [
    "### The following cells allow the creation of numpy arrays from the original NetCDF model files.  \n",
    "#### The user can skip to the cell `ls data/rcp26/*fmr.npy` to use pre-processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49deddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading NorESM1-M (process_FMR)████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅| 22/96\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-84234e950a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodelName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mresampled_gmT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_mean_T\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         method = method, verbose = False, rcp45 = rcp45)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodelFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMFDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcp45\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcp45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "for mod in range(9):\n",
    "    modelName = fileNameCodes[0][mod]\n",
    "    method = \"max\"\n",
    "    rcp45 = True\n",
    "    \n",
    "    global_mean_T, global_mean_T_df = global_mean_temp(\n",
    "        modelName=modelName,\n",
    "        method = method, verbose = False, rcp45 = rcp45)\n",
    "    \n",
    "#     heavy_rain, heavy_rain_reshaped, lat_vals, lon_vals = process_FMR(\n",
    "#         modelName=modelName,\n",
    "#         resampled_gmT=global_mean_T,\n",
    "#         method = method, verbose = False, rcp45 = rcp45, return_lat_lon = False)\n",
    "    heavy_rain, heavy_rain_reshaped = process_FMR(\n",
    "        modelName=modelName,\n",
    "        resampled_gmT=global_mean_T,\n",
    "        method = method, verbose = False, rcp45 = rcp45)\n",
    "\n",
    "    modelFile = netCDF4.MFDataset(list_of_models(parameter=\"pr\", modelName=modelName, rcp45=rcp45))\n",
    "    lat_vals = modelFile.variables[\"lat\"][:]\n",
    "    lon_vals = modelFile.variables[\"lon\"][:]\n",
    "    modelFile.close()\n",
    "    rcp = \"rcp45\"\n",
    "    np.save(\"data/rcp45/{}_{}_fmr\".format(modelName,rcp), heavy_rain_reshaped, allow_pickle=True, fix_imports=True)\n",
    "#     np.save(\"data/{}_{}_fmr\".format(modelName,rcp), heavy_rain_reshaped, allow_pickle=True, fix_imports=True)\n",
    "    latitudes = [x for x in lat_vals]\n",
    "    longitudes = [x for x in lon_vals]\n",
    "    np.save(\"data/rcp45/{}_{}_lats\".format(modelName,rcp), latitudes, allow_pickle=True, fix_imports=True)\n",
    "    np.save(\"data/rcp45/{}_{}_lons\".format(modelName,rcp), longitudes, allow_pickle=True, fix_imports=True)\n",
    "    \n",
    "    print(\"\\n\\u2713 {} processed and saved.\\n\".format(modelName))\n",
    "#     print(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7885cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jamiefarquharson/Documents/GitHub/rainfall-in-volcanic-regions'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50613ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_forcing_project_conda",
   "language": "python",
   "name": "climate_forcing_project_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
